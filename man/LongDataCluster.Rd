% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LongDataCluster.R
\name{LongDataCluster}
\alias{LongDataCluster}
\title{Clustering longitudinal data (Main Function)}
\usage{
LongDataCluster(
  x,
  Y,
  id,
  DistMetric = "W",
  functional = "bs",
  preprocess = TRUE,
  weight.func = "standardize",
  No.Class = NULL,
  parallel = FALSE,
  stop = 20,
  part.size = 300,
  ...
)
}
\arguments{
\item{x}{A vector in long format, occassions or time of observation times}

\item{Y}{A matrix, if multiple outcomes exist; or a (column) vector, for single outcome case}

\item{id}{A vector with same length of x, represents the corresponding subject id of each observation}

\item{DistMetric}{\code{c("W", "UnW")} for Weighted or Unweighted distance metric. Default is \code{Weighted}. See details.}

\item{functional}{A string from \code{c("bs", "ns")}, indicating b-splines or natural splines}

\item{preprocess}{boolean, whether data pre-processing procedure should be applied. Default is \code{TRUE} to handle 
subjects with observations less than number of parameters. If set to \code{FALSE}, those subjects will be excluded}

\item{weight.func}{A string from \code{c("standardize", "softmax", "equal")}, a method to handle weights across multiple outcomes. 
Default is \code{"standardize"}, but \code{"softmax"} is recommended for cases with a lot noise (indistinguishable) outcomes.
Select \code{"equal"} then all outcomes are forced to be treated equally.}

\item{No.Class}{Optional, the number of clusters if user has a priori in mind. Default is \code{NULL}.}

\item{parallel}{If \code{TRUE}, use parallel foreach to cluster each ubgroup of original data. 
Must register parallel beforehand, such as doMC or others}

\item{stop}{An integer, only required in parallel computing. It indicates when to stop hierarchical 
clustering process in each slave/server. See details}

\item{part.size}{In parallel computing, the (rough) number of subjects in each random partitions. See more in details}

\item{...}{Additional arguments for the functional bases. The default is cubic B-spline with 3 interval knots}
}
\value{
A list object containing the hierarchical clustering results, and some ancillary outputs for parallel computing.
\item{Cluster.res}{A list with length equal to the number of clusters determined by \eqn{Gap_b} index. Each list element consists of the corresponding subjects' id. 
                   In particular, it is equivalent to \code{out.ID[[No.Gapb]]}}
\item{Cluster.Lists}{List of hierarchical results where the length should be the number of subjects when \code{parallel = FALSE}. 
                     This is the main output. The rest elements in returns are used to facilitate other functions}
\item{No.Gapb}{Number of clusters determined by \eqn{Gap_b} statistic}
\item{No.CH}{Number of clusters determined by CH index}
\item{Dat.label}{Original dataset with labels and the number of cluster determined either by proposed \eqn{Gap_b} \code{}}
}
\description{
Clustering longitudinal data, expecially tailored for those observational longitudinal data with sparse and irregular observations. The output could be a vector, i.e., at each occasion, more than one measure are observed for each subject
}
\details{
There are two distance metrics available, one is so-called unweighted \code{UnW}, i.e. \cr
         \eqn{Dist = SSR(both) - SSR(cluster 1) - SSR(cluster 2)}. 
         \cr The other is weighted \code{W}, \cr
         \eqn{ Dist = ({SSR(both) - SSR(cluster 1) - SSR(cluster 2)}/p) / ({(SSR(cluster 1) + SSR(cluster 2))/(n_1+n_2-p)}) },
         \cr where \eqn{p} is the number of basis function, and \eqn{n_1} and \eqn{n_2} are the sample size for cluster 1
         and 2, respectively. Two metric can yield slightly different results. 
         \cr \cr
         For relatively large sample size, in terms of the number of subjects not observations, we suggest to apply parallel computing to save time dramatically.
         By specifying \code{part.size} and \code{stop}, the algorithm actually split data into multiple random partitions with size roughly 
         equal to \code{part.size}, and then apply the hierarchical algorithm in a parallel fashion on each partition until the number of clusters goes down to \code{stop}.
         Then combine the output clusters together. If the remaining number of clusters is still larger than part.size, multiple rounds of this process will be implemented.
         Otherwise, the last round will combine all the clusters until only one final node left.
}
\examples{
output = LongDataCluster(Longdat$Dat$obs,
Longdat$Dat[,paste("y", seq(5), sep = "_")], Longdat$Dat$id)
# parallel version
\dontrun{
require(doMC)
registerDoMC(cores = 6)
output = LongDataCluster(Longdat2$Dat$obs,
Longdat2$Dat[,paste("y", seq(5), sep = "_")],
Longdat2$Dat$id, parallel = T, stop = 15, part.size = 200)
}
}
\seealso{
\code{\link{MeanPlot}}, \code{\link{DendroPlot}}
}
\author{
Junyi Zhou <\email{junyzhou@iu.edu}>
}
